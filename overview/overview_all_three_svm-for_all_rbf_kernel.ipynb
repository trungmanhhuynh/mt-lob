{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from lob_data_utils import lob, db_result, model, stocks_numbers\n",
    "from lob_data_utils.svm_calculation import lob_svm\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 24000\n",
    "stocks = stocks_numbers.chosen_stocks\n",
    "should_save_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stocks = {}\n",
    "d_cv_stocks = {}\n",
    "d_test_stocks = {}\n",
    "for s in stocks:\n",
    "    d,  d_test = lob.load_prepared_data(s, length=data_length)\n",
    "    d.index = pd.to_datetime(d['Unnamed: 0'].values)\n",
    "    d_test.index = pd.to_datetime(d_test['Unnamed: 0'].values)\n",
    "    d['prev_queue_imbalance'] = [None] + d['queue_imbalance'].iloc[0:len(d)-1].values.tolist()\n",
    "    d.dropna(inplace=True)\n",
    "    d_test['prev_queue_imbalance'] = [None] + d_test['queue_imbalance'].iloc[0:len(d_test)-1].values.tolist()\n",
    "    d_test.dropna(inplace=True)\n",
    "    d_stocks[s] = d\n",
    "    d_test_stocks[s] = d_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>sum_sell_ask</th>\n",
       "      <th>sum_buy_bid</th>\n",
       "      <th>mid_price_indicator</th>\n",
       "      <th>queue_imbalance</th>\n",
       "      <th>prev_queue_imbalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:31:00</th>\n",
       "      <td>2013-09-02 08:31:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 19522.0), (750.0, 51865.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>19522.0</td>\n",
       "      <td>8078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.414638</td>\n",
       "      <td>-0.573878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:32:00</th>\n",
       "      <td>2013-09-02 08:32:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 13371.0), (750.0, 51046.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>13371.0</td>\n",
       "      <td>16818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114181</td>\n",
       "      <td>-0.414638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:33:00</th>\n",
       "      <td>2013-09-02 08:33:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 20645.0), (750.0, 51474.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>20645.0</td>\n",
       "      <td>7206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.482532</td>\n",
       "      <td>0.114181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:34:00</th>\n",
       "      <td>2013-09-02 08:34:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 14676.0), (750.0, 51474.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>14676.0</td>\n",
       "      <td>7206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.341376</td>\n",
       "      <td>-0.482532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:35:00</th>\n",
       "      <td>2013-09-02 08:35:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.0, 9652.0), (749.5, 35846.0), (750.0, 42...</td>\n",
       "      <td>748.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>748.5</td>\n",
       "      <td>9652.0</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.282914</td>\n",
       "      <td>-0.341376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Unnamed: 0  \\\n",
       "2013-09-02 08:31:00  2013-09-02 08:31:00   \n",
       "2013-09-02 08:32:00  2013-09-02 08:32:00   \n",
       "2013-09-02 08:33:00  2013-09-02 08:33:00   \n",
       "2013-09-02 08:34:00  2013-09-02 08:34:00   \n",
       "2013-09-02 08:35:00  2013-09-02 08:35:00   \n",
       "\n",
       "                                                                   bid  \\\n",
       "2013-09-02 08:31:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:32:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:33:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:34:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:35:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "\n",
       "                                                                   ask  \\\n",
       "2013-09-02 08:31:00  [(749.5, 19522.0), (750.0, 51865.0), (750.5, 1...   \n",
       "2013-09-02 08:32:00  [(749.5, 13371.0), (750.0, 51046.0), (750.5, 1...   \n",
       "2013-09-02 08:33:00  [(749.5, 20645.0), (750.0, 51474.0), (750.5, 1...   \n",
       "2013-09-02 08:34:00  [(749.5, 14676.0), (750.0, 51474.0), (750.5, 1...   \n",
       "2013-09-02 08:35:00  [(749.0, 9652.0), (749.5, 35846.0), (750.0, 42...   \n",
       "\n",
       "                     bid_price  ask_price  mid_price  sum_sell_ask  \\\n",
       "2013-09-02 08:31:00      748.5      749.5      749.0       19522.0   \n",
       "2013-09-02 08:32:00      748.5      749.5      749.0       13371.0   \n",
       "2013-09-02 08:33:00      748.5      749.5      749.0       20645.0   \n",
       "2013-09-02 08:34:00      748.5      749.5      749.0       14676.0   \n",
       "2013-09-02 08:35:00      748.0      749.0      748.5        9652.0   \n",
       "\n",
       "                     sum_buy_bid  mid_price_indicator  queue_imbalance  \\\n",
       "2013-09-02 08:31:00       8078.0                  0.0        -0.414638   \n",
       "2013-09-02 08:32:00      16818.0                  0.0         0.114181   \n",
       "2013-09-02 08:33:00       7206.0                  0.0        -0.482532   \n",
       "2013-09-02 08:34:00       7206.0                  0.0        -0.341376   \n",
       "2013-09-02 08:35:00       5395.0                  1.0        -0.282914   \n",
       "\n",
       "                     prev_queue_imbalance  \n",
       "2013-09-02 08:31:00             -0.573878  \n",
       "2013-09-02 08:32:00             -0.414638  \n",
       "2013-09-02 08:33:00              0.114181  \n",
       "2013-09-02 08:34:00             -0.482532  \n",
       "2013-09-02 08:35:00             -0.341376  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_stocks['3459'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with queue imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = {}\n",
    "for s in stocks:\n",
    "#    df_res_temp = pd.read_csv('../svm_queue_imbalance/res_svm/svm_linear_{}_len{}.csv'.format(s, data_length))\n",
    "#    df_res_temp = df_res_temp.append(pd.read_csv('../svm_queue_imbalance/res_svm/svm_sigmoid_{}_len{}.csv'.format(s, data_length)))\n",
    "    df_res_temp = pd.read_csv(\n",
    "        '../svm_queue_imbalance/res_svm/svm_rbf_{}_len{}.csv'.format(s, data_length))\n",
    "    df_res[s] = df_res_temp\n",
    "    df_res[s].index = list(range(len(df_res[s])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>coef0</th>\n",
       "      <th>f1</th>\n",
       "      <th>features</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kernel</th>\n",
       "      <th>matthews</th>\n",
       "      <th>precision</th>\n",
       "      <th>...</th>\n",
       "      <th>train_matthews</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_val_f1</th>\n",
       "      <th>train_val_kappa</th>\n",
       "      <th>train_val_matthews</th>\n",
       "      <th>train_val_precision</th>\n",
       "      <th>train_val_recall</th>\n",
       "      <th>train_val_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.472349</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.101540</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.103318</td>\n",
       "      <td>0.498954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.480375</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.543119</td>\n",
       "      <td>0.457277</td>\n",
       "      <td>0.073448</td>\n",
       "      <td>0.073929</td>\n",
       "      <td>0.475918</td>\n",
       "      <td>0.442802</td>\n",
       "      <td>0.536402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346056</td>\n",
       "      <td>que</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.092044</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.121997</td>\n",
       "      <td>0.235344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129706</td>\n",
       "      <td>0.248281</td>\n",
       "      <td>0.623704</td>\n",
       "      <td>0.581676</td>\n",
       "      <td>0.363850</td>\n",
       "      <td>0.108703</td>\n",
       "      <td>0.135944</td>\n",
       "      <td>0.254718</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>0.584868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440988</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.110685</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.124306</td>\n",
       "      <td>0.346020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.347967</td>\n",
       "      <td>0.574540</td>\n",
       "      <td>0.565546</td>\n",
       "      <td>0.436963</td>\n",
       "      <td>0.108809</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>0.345596</td>\n",
       "      <td>0.596876</td>\n",
       "      <td>0.565901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427307</td>\n",
       "      <td>que</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.155044</td>\n",
       "      <td>0.373604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126633</td>\n",
       "      <td>0.358512</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.569134</td>\n",
       "      <td>0.417938</td>\n",
       "      <td>0.121034</td>\n",
       "      <td>0.130294</td>\n",
       "      <td>0.357596</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>0.568021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294126</td>\n",
       "      <td>que</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.111888</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.147542</td>\n",
       "      <td>0.194451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145353</td>\n",
       "      <td>0.210925</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.600439</td>\n",
       "      <td>0.320966</td>\n",
       "      <td>0.120498</td>\n",
       "      <td>0.153410</td>\n",
       "      <td>0.217568</td>\n",
       "      <td>0.614933</td>\n",
       "      <td>0.604691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499682</td>\n",
       "      <td>que</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.058720</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.058888</td>\n",
       "      <td>0.481040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.480170</td>\n",
       "      <td>0.537312</td>\n",
       "      <td>0.531169</td>\n",
       "      <td>0.508247</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.065612</td>\n",
       "      <td>0.480650</td>\n",
       "      <td>0.539261</td>\n",
       "      <td>0.532976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420861</td>\n",
       "      <td>que</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.125429</td>\n",
       "      <td>0.336286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126562</td>\n",
       "      <td>0.328360</td>\n",
       "      <td>0.575441</td>\n",
       "      <td>0.571241</td>\n",
       "      <td>0.410046</td>\n",
       "      <td>0.118572</td>\n",
       "      <td>0.127730</td>\n",
       "      <td>0.330979</td>\n",
       "      <td>0.542710</td>\n",
       "      <td>0.571121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426426</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.129171</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.142003</td>\n",
       "      <td>0.336219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123290</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>0.586162</td>\n",
       "      <td>0.568791</td>\n",
       "      <td>0.433357</td>\n",
       "      <td>0.108628</td>\n",
       "      <td>0.122284</td>\n",
       "      <td>0.335616</td>\n",
       "      <td>0.612037</td>\n",
       "      <td>0.567827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263692</td>\n",
       "      <td>que</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.118773</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.144224</td>\n",
       "      <td>0.251364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.191234</td>\n",
       "      <td>0.492023</td>\n",
       "      <td>0.571478</td>\n",
       "      <td>0.253190</td>\n",
       "      <td>0.091697</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0.188974</td>\n",
       "      <td>0.429891</td>\n",
       "      <td>0.566370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448072</td>\n",
       "      <td>que</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.126557</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.139459</td>\n",
       "      <td>0.371540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147411</td>\n",
       "      <td>0.388610</td>\n",
       "      <td>0.544145</td>\n",
       "      <td>0.578951</td>\n",
       "      <td>0.445720</td>\n",
       "      <td>0.140663</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>0.387131</td>\n",
       "      <td>0.554485</td>\n",
       "      <td>0.577872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481337</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.103028</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.113982</td>\n",
       "      <td>0.415172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104075</td>\n",
       "      <td>0.419001</td>\n",
       "      <td>0.496106</td>\n",
       "      <td>0.553597</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>0.090022</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>0.407551</td>\n",
       "      <td>0.610437</td>\n",
       "      <td>0.549513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417536</td>\n",
       "      <td>que</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.107229</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.125160</td>\n",
       "      <td>0.315132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111312</td>\n",
       "      <td>0.323673</td>\n",
       "      <td>0.581426</td>\n",
       "      <td>0.562444</td>\n",
       "      <td>0.420401</td>\n",
       "      <td>0.098729</td>\n",
       "      <td>0.111316</td>\n",
       "      <td>0.325247</td>\n",
       "      <td>0.597476</td>\n",
       "      <td>0.561869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>que</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.110681</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>0.354970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122878</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.566522</td>\n",
       "      <td>0.441057</td>\n",
       "      <td>0.115786</td>\n",
       "      <td>0.123076</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>0.559764</td>\n",
       "      <td>0.566668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404931</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.127720</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.141936</td>\n",
       "      <td>0.317911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128869</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.612510</td>\n",
       "      <td>0.574176</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.110820</td>\n",
       "      <td>0.125885</td>\n",
       "      <td>0.304027</td>\n",
       "      <td>0.586544</td>\n",
       "      <td>0.572481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476034</td>\n",
       "      <td>que</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.078051</td>\n",
       "      <td>0.440687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079885</td>\n",
       "      <td>0.444249</td>\n",
       "      <td>0.491869</td>\n",
       "      <td>0.540497</td>\n",
       "      <td>0.479574</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>0.444992</td>\n",
       "      <td>0.520419</td>\n",
       "      <td>0.544064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C  Unnamed: 0  coef0        f1 features    gamma     kappa kernel  \\\n",
       "23     1.00        23.0    NaN  0.472349      que    0.100  0.101540    rbf   \n",
       "35   100.00        35.0    NaN  0.346056      que    0.001  0.092044    rbf   \n",
       "9      0.01         9.0    NaN  0.440988      que    0.100  0.110685    rbf   \n",
       "12     0.01        12.0    NaN  0.427307      que  100.000  0.146800    rbf   \n",
       "38   100.00        38.0    NaN  0.294126      que    1.000  0.111888    rbf   \n",
       "28    10.00        28.0    NaN  0.499682      que    0.001  0.058720    rbf   \n",
       "40   100.00        40.0    NaN  0.420861      que  100.000  0.112200    rbf   \n",
       "30    10.00        30.0    NaN  0.426426      que    0.100  0.129171    rbf   \n",
       "43  1000.00        43.0    NaN  0.263692      que    0.010  0.118773    rbf   \n",
       "43  1000.00        43.0    NaN  0.448072      que    0.010  0.126557    rbf   \n",
       "23     1.00        23.0    NaN  0.481337      que    0.100  0.103028    rbf   \n",
       "25     1.00        25.0    NaN  0.417536      que   10.000  0.107229    rbf   \n",
       "28    10.00        28.0    NaN  0.431032      que    0.001  0.110681    rbf   \n",
       "16     0.10        16.0    NaN  0.404931      que    0.100  0.127720    rbf   \n",
       "42  1000.00        42.0    NaN  0.476034      que    0.001  0.077145    rbf   \n",
       "\n",
       "    matthews  precision        ...          train_matthews  train_precision  \\\n",
       "23  0.103318   0.498954        ...                0.085900         0.480375   \n",
       "35  0.121997   0.235344        ...                0.129706         0.248281   \n",
       "9   0.124306   0.346020        ...                0.119259         0.347967   \n",
       "12  0.155044   0.373604        ...                0.126633         0.358512   \n",
       "38  0.147542   0.194451        ...                0.145353         0.210925   \n",
       "28  0.058888   0.481040        ...                0.062020         0.480170   \n",
       "40  0.125429   0.336286        ...                0.126562         0.328360   \n",
       "30  0.142003   0.336219        ...                0.123290         0.334475   \n",
       "43  0.144224   0.251364        ...                0.103875         0.191234   \n",
       "43  0.139459   0.371540        ...                0.147411         0.388610   \n",
       "23  0.113982   0.415172        ...                0.104075         0.419001   \n",
       "25  0.125160   0.315132        ...                0.111312         0.323673   \n",
       "28  0.117545   0.354970        ...                0.122878         0.366460   \n",
       "16  0.141936   0.317911        ...                0.128869         0.308100   \n",
       "42  0.078051   0.440687        ...                0.079885         0.444249   \n",
       "\n",
       "    train_recall  train_roc_auc  train_val_f1  train_val_kappa  \\\n",
       "23      0.498738       0.543119      0.457277         0.073448   \n",
       "35      0.623704       0.581676      0.363850         0.108703   \n",
       "9       0.574540       0.565546      0.436963         0.108809   \n",
       "12      0.556612       0.569134      0.417938         0.121034   \n",
       "38      0.583799       0.600439      0.320966         0.120498   \n",
       "28      0.537312       0.531169      0.508247         0.065208   \n",
       "40      0.575441       0.571241      0.410046         0.118572   \n",
       "30      0.586162       0.568791      0.433357         0.108628   \n",
       "43      0.492023       0.571478      0.253190         0.091697   \n",
       "43      0.544145       0.578951      0.445720         0.140663   \n",
       "23      0.496106       0.553597      0.482178         0.090022   \n",
       "25      0.581426       0.562444      0.420401         0.098729   \n",
       "28      0.561905       0.566522      0.441057         0.115786   \n",
       "16      0.612510       0.574176      0.399769         0.110820   \n",
       "42      0.491869       0.540497      0.479574         0.085725   \n",
       "\n",
       "    train_val_matthews  train_val_precision  train_val_recall  \\\n",
       "23            0.073929             0.475918          0.442802   \n",
       "35            0.135944             0.254718          0.636720   \n",
       "9             0.120391             0.345596          0.596876   \n",
       "12            0.130294             0.357596          0.530188   \n",
       "38            0.153410             0.217568          0.614933   \n",
       "28            0.065612             0.480650          0.539261   \n",
       "40            0.127730             0.330979          0.542710   \n",
       "30            0.122284             0.335616          0.612037   \n",
       "43            0.104858             0.188974          0.429891   \n",
       "43            0.151609             0.387131          0.554485   \n",
       "23            0.098840             0.407551          0.610437   \n",
       "25            0.111316             0.325247          0.597476   \n",
       "28            0.123076             0.364089          0.559764   \n",
       "16            0.125885             0.304027          0.586544   \n",
       "42            0.086590             0.444992          0.520419   \n",
       "\n",
       "    train_val_roc_auc  \n",
       "23           0.536402  \n",
       "35           0.584868  \n",
       "9            0.565901  \n",
       "12           0.568021  \n",
       "38           0.604691  \n",
       "28           0.532976  \n",
       "40           0.571121  \n",
       "30           0.567827  \n",
       "43           0.566370  \n",
       "43           0.577872  \n",
       "23           0.549513  \n",
       "25           0.561869  \n",
       "28           0.566668  \n",
       "16           0.572481  \n",
       "42           0.544064  \n",
       "\n",
       "[15 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_svm = pd.DataFrame()\n",
    "for s in stocks:\n",
    "    idx_max = df_res[s]['matthews'].idxmax()\n",
    "    df_best_svm = df_best_svm.append(df_res[s].loc[idx_max])\n",
    "df_best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrlrrr}\n",
      "\\toprule\n",
      "{} &    stock & kernel &        C &    gamma &  coef0 \\\\\n",
      "\\midrule\n",
      "23 &   9061.0 &    rbf &     1.00 &    0.100 &    NaN \\\\\n",
      "35 &   3459.0 &    rbf &   100.00 &    0.001 &    NaN \\\\\n",
      "9  &   4549.0 &    rbf &     0.01 &    0.100 &    NaN \\\\\n",
      "12 &   9761.0 &    rbf &     0.01 &  100.000 &    NaN \\\\\n",
      "38 &   4851.0 &    rbf &   100.00 &    1.000 &    NaN \\\\\n",
      "28 &   9062.0 &    rbf &    10.00 &    0.001 &    NaN \\\\\n",
      "40 &  11869.0 &    rbf &   100.00 &  100.000 &    NaN \\\\\n",
      "30 &  12255.0 &    rbf &    10.00 &    0.100 &    NaN \\\\\n",
      "43 &   2748.0 &    rbf &  1000.00 &    0.010 &    NaN \\\\\n",
      "43 &   4320.0 &    rbf &  1000.00 &    0.010 &    NaN \\\\\n",
      "23 &  11583.0 &    rbf &     1.00 &    0.100 &    NaN \\\\\n",
      "25 &   4799.0 &    rbf &     1.00 &   10.000 &    NaN \\\\\n",
      "28 &   9268.0 &    rbf &    10.00 &    0.001 &    NaN \\\\\n",
      "16 &  10470.0 &    rbf &     0.10 &    0.100 &    NaN \\\\\n",
      "42 &   9058.0 &    rbf &  1000.00 &    0.001 &    NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_best_svm[['stock', 'kernel', 'C', 'gamma', 'coef0']].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn import utils\n",
    "\n",
    "def get_classes_weights(y_train):\n",
    "    classes = np.unique(y_train)\n",
    "    class_weight_list = utils.class_weight.compute_class_weight('balanced', classes, y_train)\n",
    "    class_weights = {classes[0]: class_weight_list[0], classes[1]: class_weight_list[1]}\n",
    "    return class_weights\n",
    "\n",
    "def fit_best_svm_classifier(df_best_svm, df, stock=None):\n",
    "    stock = int(stock)\n",
    "    gamma = df_best_svm[df_best_svm['stock'] == stock]['gamma'].values[0]\n",
    "    coef0 = df_best_svm[df_best_svm['stock'] == stock]['coef0'].values[0]\n",
    "    c = df_best_svm[df_best_svm['stock'] == stock]['C'].values[0]\n",
    "    kernel = df_best_svm[df_best_svm['stock'] == stock]['kernel'].values[0]\n",
    "\n",
    "    X = df['queue_imbalance'].values.reshape(-1, 1)\n",
    "    y = df['mid_price_indicator']\n",
    "   \n",
    "    weights = get_classes_weights(y)\n",
    "    clf = SVC(gamma=gamma, C=c, coef0=coef0, kernel=kernel, random_state=23131, class_weight=weights)\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_dict_for_data(functions_to_run, dfs, log_clf, stock):\n",
    "    scores = {'stock': stock}\n",
    "    for func_name, func in functions_to_run.items():\n",
    "        for df_name, df in dfs.items():\n",
    "            pred = log_clf.predict(df['queue_imbalance'].values.reshape(-1, 1))\n",
    "            df['pred'] = pred\n",
    "            scores['{}_{}'.format(df_name, func_name)] = func(df['mid_price_indicator'], pred)\n",
    "    return scores\n",
    "            \n",
    "functions_to_run = {'precision': metrics.precision_score, 'roc_auc': metrics.roc_auc_score,\n",
    "                   'f1_score': metrics.f1_score, 'recall': metrics.recall_score, \n",
    "                   'matthews': metrics.matthews_corrcoef, 'kappa': metrics.cohen_kappa_score}\n",
    "scores = []\n",
    "for stock in stocks:\n",
    "    log_clf = fit_best_svm_classifier(df_best_svm, d_stocks[stock], stock=stock)\n",
    "    dfs = {'train': d_stocks[stock], 'test': d_test_stocks[stock], }\n",
    "    res_validation = model.validate_model(\n",
    "        fit_best_svm_classifier(df_best_svm, d_stocks[stock], stock=stock), \n",
    "        d_stocks[stock][['queue_imbalance']], d_stocks[stock]['mid_price_indicator'])\n",
    "    res = get_scores_dict_for_data(functions_to_run, dfs, log_clf, stock)\n",
    "    res = {**res, **res_validation}\n",
    "    scores.append(res)\n",
    "df_scores = pd.DataFrame(scores, index=stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>kappa</th>\n",
       "      <th>matthews</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>stock</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_kappa</th>\n",
       "      <th>test_matthews</th>\n",
       "      <th>...</th>\n",
       "      <th>train_matthews</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_val_f1</th>\n",
       "      <th>train_val_kappa</th>\n",
       "      <th>train_val_matthews</th>\n",
       "      <th>train_val_precision</th>\n",
       "      <th>train_val_recall</th>\n",
       "      <th>train_val_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>0.472349</td>\n",
       "      <td>0.101540</td>\n",
       "      <td>0.103318</td>\n",
       "      <td>0.498954</td>\n",
       "      <td>0.458067</td>\n",
       "      <td>0.550456</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.489767</td>\n",
       "      <td>0.093031</td>\n",
       "      <td>0.093155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.480375</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.543119</td>\n",
       "      <td>[0.4706038840117052, 0.42621015348288077, 0.44...</td>\n",
       "      <td>[0.06988393711482777, 0.06802447662437316, 0.0...</td>\n",
       "      <td>[0.06988470046291312, 0.06896324503448231, 0.0...</td>\n",
       "      <td>[0.4718591624433182, 0.4742200328407225, 0.477...</td>\n",
       "      <td>[0.46935526664897853, 0.38702760653980167, 0.4...</td>\n",
       "      <td>[0.5349197640750947, 0.5332214524489157, 0.536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0.346056</td>\n",
       "      <td>0.092044</td>\n",
       "      <td>0.121997</td>\n",
       "      <td>0.235344</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.577255</td>\n",
       "      <td>3459</td>\n",
       "      <td>0.355655</td>\n",
       "      <td>0.112362</td>\n",
       "      <td>0.134119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129706</td>\n",
       "      <td>0.248281</td>\n",
       "      <td>0.623704</td>\n",
       "      <td>0.581676</td>\n",
       "      <td>[0.3681575972872598, 0.37060601240655316, 0.36...</td>\n",
       "      <td>[0.11123153964811283, 0.11014490213541817, 0.1...</td>\n",
       "      <td>[0.13980026328240328, 0.13932066642959165, 0.1...</td>\n",
       "      <td>[0.25733634311512416, 0.2586015538290788, 0.25...</td>\n",
       "      <td>[0.6466250709018718, 0.6537598204264871, 0.617...</td>\n",
       "      <td>[0.5870298580593817, 0.5863498799669523, 0.586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>0.440988</td>\n",
       "      <td>0.110685</td>\n",
       "      <td>0.124306</td>\n",
       "      <td>0.346020</td>\n",
       "      <td>0.614044</td>\n",
       "      <td>0.567872</td>\n",
       "      <td>4549</td>\n",
       "      <td>0.431774</td>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.132924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.347967</td>\n",
       "      <td>0.574540</td>\n",
       "      <td>0.565546</td>\n",
       "      <td>[0.4321115892565663, 0.4303723248314278, 0.426...</td>\n",
       "      <td>[0.10824648945870152, 0.10205806537659579, 0.1...</td>\n",
       "      <td>[0.11719820879578352, 0.11141502471611715, 0.1...</td>\n",
       "      <td>[0.3473282442748092, 0.3430708109371348, 0.349...</td>\n",
       "      <td>[0.5716529250098155, 0.5772709398348408, 0.547...</td>\n",
       "      <td>[0.5643955787237488, 0.5612818626705747, 0.571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.427307</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.155044</td>\n",
       "      <td>0.373604</td>\n",
       "      <td>0.521666</td>\n",
       "      <td>0.581671</td>\n",
       "      <td>9761</td>\n",
       "      <td>0.435133</td>\n",
       "      <td>0.104244</td>\n",
       "      <td>0.111120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126633</td>\n",
       "      <td>0.358512</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.569134</td>\n",
       "      <td>[0.4713876967095851, 0.447856856723194, 0.3924...</td>\n",
       "      <td>[0.09451154861061384, 0.10255392922569206, 0.1...</td>\n",
       "      <td>[0.12136483848321863, 0.12030771209813824, 0.1...</td>\n",
       "      <td>[0.3450261780104712, 0.33885633461305315, 0.35...</td>\n",
       "      <td>[0.7437923250564334, 0.6602362204724409, 0.433...</td>\n",
       "      <td>[0.562599970011322, 0.5656071967358163, 0.5645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>0.294126</td>\n",
       "      <td>0.111888</td>\n",
       "      <td>0.147542</td>\n",
       "      <td>0.194451</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.605738</td>\n",
       "      <td>4851</td>\n",
       "      <td>0.290175</td>\n",
       "      <td>0.109623</td>\n",
       "      <td>0.142386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145353</td>\n",
       "      <td>0.210925</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.600439</td>\n",
       "      <td>[0.32042862080884893, 0.3298245614035088, 0.32...</td>\n",
       "      <td>[0.09861236009346741, 0.11263685312505878, 0.1...</td>\n",
       "      <td>[0.13340960473703764, 0.1504535864089527, 0.16...</td>\n",
       "      <td>[0.2125171939477304, 0.21978021978021978, 0.22...</td>\n",
       "      <td>[0.6509831460674157, 0.6605762473647224, 0.625...</td>\n",
       "      <td>[0.590249825327914, 0.6017890823238292, 0.6114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>0.499682</td>\n",
       "      <td>0.058720</td>\n",
       "      <td>0.058888</td>\n",
       "      <td>0.481040</td>\n",
       "      <td>0.520395</td>\n",
       "      <td>0.529561</td>\n",
       "      <td>9062</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.043992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.480170</td>\n",
       "      <td>0.537312</td>\n",
       "      <td>0.531169</td>\n",
       "      <td>[0.5111459211953248, 0.5096200096200096, 0.501...</td>\n",
       "      <td>[0.07066118448352121, 0.0662540997713329, 0.06...</td>\n",
       "      <td>[0.07109769343621353, 0.0666961614740884, 0.06...</td>\n",
       "      <td>[0.4830334775677522, 0.48060784758448627, 0.47...</td>\n",
       "      <td>[0.5427328556806551, 0.5423598669055542, 0.528...</td>\n",
       "      <td>[0.5357425955795844, 0.5335294560762722, 0.531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>0.420861</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.125429</td>\n",
       "      <td>0.336286</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0.568426</td>\n",
       "      <td>11869</td>\n",
       "      <td>0.411279</td>\n",
       "      <td>0.095819</td>\n",
       "      <td>0.101515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126562</td>\n",
       "      <td>0.328360</td>\n",
       "      <td>0.575441</td>\n",
       "      <td>0.571241</td>\n",
       "      <td>[0.3963035365203484, 0.3935553946415641, 0.401...</td>\n",
       "      <td>[0.1253850383861712, 0.12688125853963372, 0.11...</td>\n",
       "      <td>[0.1309157757867545, 0.13177593713767335, 0.12...</td>\n",
       "      <td>[0.3306642941874259, 0.33140243902439026, 0.33...</td>\n",
       "      <td>[0.49445676274944567, 0.48440285204991085, 0.5...</td>\n",
       "      <td>[0.5728079795200087, 0.5730145721443815, 0.569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>0.426426</td>\n",
       "      <td>0.129171</td>\n",
       "      <td>0.142003</td>\n",
       "      <td>0.336219</td>\n",
       "      <td>0.587918</td>\n",
       "      <td>0.579604</td>\n",
       "      <td>12255</td>\n",
       "      <td>0.413164</td>\n",
       "      <td>0.099721</td>\n",
       "      <td>0.110026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123290</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>0.586162</td>\n",
       "      <td>0.568791</td>\n",
       "      <td>[0.4358176653591235, 0.42294322132097334, 0.41...</td>\n",
       "      <td>[0.08849640952447757, 0.09498850705908646, 0.1...</td>\n",
       "      <td>[0.10305734649456065, 0.1066561382163357, 0.12...</td>\n",
       "      <td>[0.33086876155268025, 0.32786885245901637, 0.3...</td>\n",
       "      <td>[0.6382725832012678, 0.5956752345981232, 0.565...</td>\n",
       "      <td>[0.5564367270142769, 0.5593135497185706, 0.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.263692</td>\n",
       "      <td>0.118773</td>\n",
       "      <td>0.144224</td>\n",
       "      <td>0.251364</td>\n",
       "      <td>0.439015</td>\n",
       "      <td>0.586850</td>\n",
       "      <td>2748</td>\n",
       "      <td>0.294881</td>\n",
       "      <td>0.104692</td>\n",
       "      <td>0.138332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.191234</td>\n",
       "      <td>0.492023</td>\n",
       "      <td>0.571478</td>\n",
       "      <td>[0.26798265290862866, 0.1973359644795264, 0.22...</td>\n",
       "      <td>[0.04439571204071868, 0.09384905138871014, 0.1...</td>\n",
       "      <td>[0.07655149107672898, 0.09487233387968319, 0.1...</td>\n",
       "      <td>[0.16500920810313074, 0.17467248908296942, 0.1...</td>\n",
       "      <td>[0.7128082736674622, 0.22675736961451248, 0.27...</td>\n",
       "      <td>[0.5528422728808656, 0.5531338805231812, 0.562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0.448072</td>\n",
       "      <td>0.126557</td>\n",
       "      <td>0.139459</td>\n",
       "      <td>0.371540</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.574123</td>\n",
       "      <td>4320</td>\n",
       "      <td>0.436405</td>\n",
       "      <td>0.127558</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147411</td>\n",
       "      <td>0.388610</td>\n",
       "      <td>0.544145</td>\n",
       "      <td>0.578951</td>\n",
       "      <td>[0.49761987693022175, 0.48384654215042916, 0.4...</td>\n",
       "      <td>[0.11231020592467156, 0.12765228759575964, 0.1...</td>\n",
       "      <td>[0.14223483691571728, 0.15127975188267426, 0.1...</td>\n",
       "      <td>[0.3693553946914857, 0.36724137931034484, 0.40...</td>\n",
       "      <td>[0.7623621487015297, 0.7089497041420119, 0.414...</td>\n",
       "      <td>[0.5718303810805585, 0.5801848670186891, 0.578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.481337</td>\n",
       "      <td>0.103028</td>\n",
       "      <td>0.113982</td>\n",
       "      <td>0.415172</td>\n",
       "      <td>0.600367</td>\n",
       "      <td>0.556751</td>\n",
       "      <td>11583</td>\n",
       "      <td>0.433809</td>\n",
       "      <td>0.099153</td>\n",
       "      <td>0.099416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104075</td>\n",
       "      <td>0.419001</td>\n",
       "      <td>0.496106</td>\n",
       "      <td>0.553597</td>\n",
       "      <td>[0.42993024730500945, 0.45024041964155614, 0.5...</td>\n",
       "      <td>[0.10723020298177055, 0.0976577752517358, 0.07...</td>\n",
       "      <td>[0.10724132158609893, 0.0985232202573863, 0.09...</td>\n",
       "      <td>[0.42601319509896324, 0.4166666666666667, 0.39...</td>\n",
       "      <td>[0.43392, 0.4896988906497623, 0.71136292099464...</td>\n",
       "      <td>[0.5538350000000001, 0.5506842747683283, 0.545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.417536</td>\n",
       "      <td>0.107229</td>\n",
       "      <td>0.125160</td>\n",
       "      <td>0.315132</td>\n",
       "      <td>0.627954</td>\n",
       "      <td>0.570132</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.409963</td>\n",
       "      <td>0.109959</td>\n",
       "      <td>0.120548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111312</td>\n",
       "      <td>0.323673</td>\n",
       "      <td>0.581426</td>\n",
       "      <td>0.562444</td>\n",
       "      <td>[0.4400406504065041, 0.4224347081489939, 0.420...</td>\n",
       "      <td>[0.07953672167376802, 0.08980931171815043, 0.1...</td>\n",
       "      <td>[0.09912454740968576, 0.10190352736647143, 0.1...</td>\n",
       "      <td>[0.3228331780055918, 0.32498902064119456, 0.32...</td>\n",
       "      <td>[0.6908655763861189, 0.6033428454953118, 0.584...</td>\n",
       "      <td>[0.5532970532300489, 0.5566140247884722, 0.565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.431032</td>\n",
       "      <td>0.110681</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>0.354970</td>\n",
       "      <td>0.549027</td>\n",
       "      <td>0.564115</td>\n",
       "      <td>9268</td>\n",
       "      <td>0.455276</td>\n",
       "      <td>0.121795</td>\n",
       "      <td>0.131572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122878</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.566522</td>\n",
       "      <td>[0.46490377959296686, 0.45241900334156615, 0.4...</td>\n",
       "      <td>[0.12202212224238396, 0.12498269431046405, 0.1...</td>\n",
       "      <td>[0.13251754759206724, 0.13407263382306958, 0.1...</td>\n",
       "      <td>[0.3756152125279642, 0.36886993603411516, 0.36...</td>\n",
       "      <td>[0.6098801307664367, 0.5848985725018783, 0.544...</td>\n",
       "      <td>[0.5712662542646652, 0.5727560650733043, 0.570...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>0.404931</td>\n",
       "      <td>0.127720</td>\n",
       "      <td>0.141936</td>\n",
       "      <td>0.317911</td>\n",
       "      <td>0.572614</td>\n",
       "      <td>0.580575</td>\n",
       "      <td>10470</td>\n",
       "      <td>0.414752</td>\n",
       "      <td>0.114070</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128869</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.612510</td>\n",
       "      <td>0.574176</td>\n",
       "      <td>[0.41825199889716025, 0.3951982309271837, 0.37...</td>\n",
       "      <td>[0.0963577470582142, 0.10210876618607789, 0.11...</td>\n",
       "      <td>[0.11908295181631788, 0.1156938733269444, 0.12...</td>\n",
       "      <td>[0.3034606921384277, 0.30014395393474086, 0.30...</td>\n",
       "      <td>[0.6727272727272727, 0.5783633841886269, 0.502...</td>\n",
       "      <td>[0.5672755374455529, 0.5669171386045238, 0.570...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>0.476034</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>0.078051</td>\n",
       "      <td>0.440687</td>\n",
       "      <td>0.518605</td>\n",
       "      <td>0.539728</td>\n",
       "      <td>9058</td>\n",
       "      <td>0.469285</td>\n",
       "      <td>0.095219</td>\n",
       "      <td>0.095354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079885</td>\n",
       "      <td>0.444249</td>\n",
       "      <td>0.491869</td>\n",
       "      <td>0.540497</td>\n",
       "      <td>[0.48713023434498653, 0.4763048992123882, 0.47...</td>\n",
       "      <td>[0.07995407093228979, 0.08621731060456905, 0.0...</td>\n",
       "      <td>[0.0814152064306196, 0.0869576024898525, 0.089...</td>\n",
       "      <td>[0.44078794901506374, 0.4432298136645963, 0.44...</td>\n",
       "      <td>[0.544361763022324, 0.5147143681477208, 0.5179...</td>\n",
       "      <td>[0.5415366452274686, 0.5442938640510424, 0.545...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f1     kappa  matthews  precision    recall   roc_auc  stock  \\\n",
       "9061   0.472349  0.101540  0.103318   0.498954  0.458067  0.550456   9061   \n",
       "3459   0.346056  0.092044  0.121997   0.235344  0.658740  0.577255   3459   \n",
       "4549   0.440988  0.110685  0.124306   0.346020  0.614044  0.567872   4549   \n",
       "9761   0.427307  0.146800  0.155044   0.373604  0.521666  0.581671   9761   \n",
       "4851   0.294126  0.111888  0.147542   0.194451  0.615188  0.605738   4851   \n",
       "9062   0.499682  0.058720  0.058888   0.481040  0.520395  0.529561   9062   \n",
       "11869  0.420861  0.112200  0.125429   0.336286  0.585906  0.568426  11869   \n",
       "12255  0.426426  0.129171  0.142003   0.336219  0.587918  0.579604  12255   \n",
       "2748   0.263692  0.118773  0.144224   0.251364  0.439015  0.586850   2748   \n",
       "4320   0.448072  0.126557  0.139459   0.371540  0.586353  0.574123   4320   \n",
       "11583  0.481337  0.103028  0.113982   0.415172  0.600367  0.556751  11583   \n",
       "4799   0.417536  0.107229  0.125160   0.315132  0.627954  0.570132   4799   \n",
       "9268   0.431032  0.110681  0.117545   0.354970  0.549027  0.564115   9268   \n",
       "10470  0.404931  0.127720  0.141936   0.317911  0.572614  0.580575  10470   \n",
       "9058   0.476034  0.077145  0.078051   0.440687  0.518605  0.539728   9058   \n",
       "\n",
       "       test_f1_score  test_kappa  test_matthews  \\\n",
       "9061        0.489767    0.093031       0.093155   \n",
       "3459        0.355655    0.112362       0.134119   \n",
       "4549        0.431774    0.122431       0.132924   \n",
       "9761        0.435133    0.104244       0.111120   \n",
       "4851        0.290175    0.109623       0.142386   \n",
       "9062        0.500000    0.043577       0.043992   \n",
       "11869       0.411279    0.095819       0.101515   \n",
       "12255       0.413164    0.099721       0.110026   \n",
       "2748        0.294881    0.104692       0.138332   \n",
       "4320        0.436405    0.127558       0.131474   \n",
       "11583       0.433809    0.099153       0.099416   \n",
       "4799        0.409963    0.109959       0.120548   \n",
       "9268        0.455276    0.121795       0.131572   \n",
       "10470       0.414752    0.114070       0.125502   \n",
       "9058        0.469285    0.095219       0.095354   \n",
       "\n",
       "                             ...                          train_matthews  \\\n",
       "9061                         ...                                0.085900   \n",
       "3459                         ...                                0.129706   \n",
       "4549                         ...                                0.119259   \n",
       "9761                         ...                                0.126633   \n",
       "4851                         ...                                0.145353   \n",
       "9062                         ...                                0.062020   \n",
       "11869                        ...                                0.126562   \n",
       "12255                        ...                                0.123290   \n",
       "2748                         ...                                0.103875   \n",
       "4320                         ...                                0.147411   \n",
       "11583                        ...                                0.104075   \n",
       "4799                         ...                                0.111312   \n",
       "9268                         ...                                0.122878   \n",
       "10470                        ...                                0.128869   \n",
       "9058                         ...                                0.079885   \n",
       "\n",
       "       train_precision  train_recall  train_roc_auc  \\\n",
       "9061          0.480375      0.498738       0.543119   \n",
       "3459          0.248281      0.623704       0.581676   \n",
       "4549          0.347967      0.574540       0.565546   \n",
       "9761          0.358512      0.556612       0.569134   \n",
       "4851          0.210925      0.583799       0.600439   \n",
       "9062          0.480170      0.537312       0.531169   \n",
       "11869         0.328360      0.575441       0.571241   \n",
       "12255         0.334475      0.586162       0.568791   \n",
       "2748          0.191234      0.492023       0.571478   \n",
       "4320          0.388610      0.544145       0.578951   \n",
       "11583         0.419001      0.496106       0.553597   \n",
       "4799          0.323673      0.581426       0.562444   \n",
       "9268          0.366460      0.561905       0.566522   \n",
       "10470         0.308100      0.612510       0.574176   \n",
       "9058          0.444249      0.491869       0.540497   \n",
       "\n",
       "                                            train_val_f1  \\\n",
       "9061   [0.4706038840117052, 0.42621015348288077, 0.44...   \n",
       "3459   [0.3681575972872598, 0.37060601240655316, 0.36...   \n",
       "4549   [0.4321115892565663, 0.4303723248314278, 0.426...   \n",
       "9761   [0.4713876967095851, 0.447856856723194, 0.3924...   \n",
       "4851   [0.32042862080884893, 0.3298245614035088, 0.32...   \n",
       "9062   [0.5111459211953248, 0.5096200096200096, 0.501...   \n",
       "11869  [0.3963035365203484, 0.3935553946415641, 0.401...   \n",
       "12255  [0.4358176653591235, 0.42294322132097334, 0.41...   \n",
       "2748   [0.26798265290862866, 0.1973359644795264, 0.22...   \n",
       "4320   [0.49761987693022175, 0.48384654215042916, 0.4...   \n",
       "11583  [0.42993024730500945, 0.45024041964155614, 0.5...   \n",
       "4799   [0.4400406504065041, 0.4224347081489939, 0.420...   \n",
       "9268   [0.46490377959296686, 0.45241900334156615, 0.4...   \n",
       "10470  [0.41825199889716025, 0.3951982309271837, 0.37...   \n",
       "9058   [0.48713023434498653, 0.4763048992123882, 0.47...   \n",
       "\n",
       "                                         train_val_kappa  \\\n",
       "9061   [0.06988393711482777, 0.06802447662437316, 0.0...   \n",
       "3459   [0.11123153964811283, 0.11014490213541817, 0.1...   \n",
       "4549   [0.10824648945870152, 0.10205806537659579, 0.1...   \n",
       "9761   [0.09451154861061384, 0.10255392922569206, 0.1...   \n",
       "4851   [0.09861236009346741, 0.11263685312505878, 0.1...   \n",
       "9062   [0.07066118448352121, 0.0662540997713329, 0.06...   \n",
       "11869  [0.1253850383861712, 0.12688125853963372, 0.11...   \n",
       "12255  [0.08849640952447757, 0.09498850705908646, 0.1...   \n",
       "2748   [0.04439571204071868, 0.09384905138871014, 0.1...   \n",
       "4320   [0.11231020592467156, 0.12765228759575964, 0.1...   \n",
       "11583  [0.10723020298177055, 0.0976577752517358, 0.07...   \n",
       "4799   [0.07953672167376802, 0.08980931171815043, 0.1...   \n",
       "9268   [0.12202212224238396, 0.12498269431046405, 0.1...   \n",
       "10470  [0.0963577470582142, 0.10210876618607789, 0.11...   \n",
       "9058   [0.07995407093228979, 0.08621731060456905, 0.0...   \n",
       "\n",
       "                                      train_val_matthews  \\\n",
       "9061   [0.06988470046291312, 0.06896324503448231, 0.0...   \n",
       "3459   [0.13980026328240328, 0.13932066642959165, 0.1...   \n",
       "4549   [0.11719820879578352, 0.11141502471611715, 0.1...   \n",
       "9761   [0.12136483848321863, 0.12030771209813824, 0.1...   \n",
       "4851   [0.13340960473703764, 0.1504535864089527, 0.16...   \n",
       "9062   [0.07109769343621353, 0.0666961614740884, 0.06...   \n",
       "11869  [0.1309157757867545, 0.13177593713767335, 0.12...   \n",
       "12255  [0.10305734649456065, 0.1066561382163357, 0.12...   \n",
       "2748   [0.07655149107672898, 0.09487233387968319, 0.1...   \n",
       "4320   [0.14223483691571728, 0.15127975188267426, 0.1...   \n",
       "11583  [0.10724132158609893, 0.0985232202573863, 0.09...   \n",
       "4799   [0.09912454740968576, 0.10190352736647143, 0.1...   \n",
       "9268   [0.13251754759206724, 0.13407263382306958, 0.1...   \n",
       "10470  [0.11908295181631788, 0.1156938733269444, 0.12...   \n",
       "9058   [0.0814152064306196, 0.0869576024898525, 0.089...   \n",
       "\n",
       "                                     train_val_precision  \\\n",
       "9061   [0.4718591624433182, 0.4742200328407225, 0.477...   \n",
       "3459   [0.25733634311512416, 0.2586015538290788, 0.25...   \n",
       "4549   [0.3473282442748092, 0.3430708109371348, 0.349...   \n",
       "9761   [0.3450261780104712, 0.33885633461305315, 0.35...   \n",
       "4851   [0.2125171939477304, 0.21978021978021978, 0.22...   \n",
       "9062   [0.4830334775677522, 0.48060784758448627, 0.47...   \n",
       "11869  [0.3306642941874259, 0.33140243902439026, 0.33...   \n",
       "12255  [0.33086876155268025, 0.32786885245901637, 0.3...   \n",
       "2748   [0.16500920810313074, 0.17467248908296942, 0.1...   \n",
       "4320   [0.3693553946914857, 0.36724137931034484, 0.40...   \n",
       "11583  [0.42601319509896324, 0.4166666666666667, 0.39...   \n",
       "4799   [0.3228331780055918, 0.32498902064119456, 0.32...   \n",
       "9268   [0.3756152125279642, 0.36886993603411516, 0.36...   \n",
       "10470  [0.3034606921384277, 0.30014395393474086, 0.30...   \n",
       "9058   [0.44078794901506374, 0.4432298136645963, 0.44...   \n",
       "\n",
       "                                        train_val_recall  \\\n",
       "9061   [0.46935526664897853, 0.38702760653980167, 0.4...   \n",
       "3459   [0.6466250709018718, 0.6537598204264871, 0.617...   \n",
       "4549   [0.5716529250098155, 0.5772709398348408, 0.547...   \n",
       "9761   [0.7437923250564334, 0.6602362204724409, 0.433...   \n",
       "4851   [0.6509831460674157, 0.6605762473647224, 0.625...   \n",
       "9062   [0.5427328556806551, 0.5423598669055542, 0.528...   \n",
       "11869  [0.49445676274944567, 0.48440285204991085, 0.5...   \n",
       "12255  [0.6382725832012678, 0.5956752345981232, 0.565...   \n",
       "2748   [0.7128082736674622, 0.22675736961451248, 0.27...   \n",
       "4320   [0.7623621487015297, 0.7089497041420119, 0.414...   \n",
       "11583  [0.43392, 0.4896988906497623, 0.71136292099464...   \n",
       "4799   [0.6908655763861189, 0.6033428454953118, 0.584...   \n",
       "9268   [0.6098801307664367, 0.5848985725018783, 0.544...   \n",
       "10470  [0.6727272727272727, 0.5783633841886269, 0.502...   \n",
       "9058   [0.544361763022324, 0.5147143681477208, 0.5179...   \n",
       "\n",
       "                                       train_val_roc_auc  \n",
       "9061   [0.5349197640750947, 0.5332214524489157, 0.536...  \n",
       "3459   [0.5870298580593817, 0.5863498799669523, 0.586...  \n",
       "4549   [0.5643955787237488, 0.5612818626705747, 0.571...  \n",
       "9761   [0.562599970011322, 0.5656071967358163, 0.5645...  \n",
       "4851   [0.590249825327914, 0.6017890823238292, 0.6114...  \n",
       "9062   [0.5357425955795844, 0.5335294560762722, 0.531...  \n",
       "11869  [0.5728079795200087, 0.5730145721443815, 0.569...  \n",
       "12255  [0.5564367270142769, 0.5593135497185706, 0.567...  \n",
       "2748   [0.5528422728808656, 0.5531338805231812, 0.562...  \n",
       "4320   [0.5718303810805585, 0.5801848670186891, 0.578...  \n",
       "11583  [0.5538350000000001, 0.5506842747683283, 0.545...  \n",
       "4799   [0.5532970532300489, 0.5566140247884722, 0.565...  \n",
       "9268   [0.5712662542646652, 0.5727560650733043, 0.570...  \n",
       "10470  [0.5672755374455529, 0.5669171386045238, 0.570...  \n",
       "9058   [0.5415366452274686, 0.5442938640510424, 0.545...  \n",
       "\n",
       "[15 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_scores(df, column):\n",
    "    scores = []\n",
    "    for i, row in df.iterrows():\n",
    "        scores.append(np.mean(row[column]))\n",
    "    return scores\n",
    "scores_columns = ['f1', 'kappa', 'matthews', 'precision', 'recall', 'roc_auc', 'train_f1', 'train_kappa',\n",
    "       'train_matthews', 'train_precision', 'train_recall', 'train_roc_auc']\n",
    "\n",
    "for col in scores_columns:\n",
    "    df_scores[col] = convert_scores(df_scores, col)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pivot</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>0.111936</td>\n",
       "      <td>9061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0.063351</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>0.020534</td>\n",
       "      <td>4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.071641</td>\n",
       "      <td>9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>0.121941</td>\n",
       "      <td>4851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>0.004079</td>\n",
       "      <td>9062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>0.038638</td>\n",
       "      <td>11869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>0.023962</td>\n",
       "      <td>12255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.158208</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0.130297</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.143343</td>\n",
       "      <td>11583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.033953</td>\n",
       "      <td>4799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.022682</td>\n",
       "      <td>9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>0.057413</td>\n",
       "      <td>10470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>0.120599</td>\n",
       "      <td>9058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pivot  stock\n",
       "9061   0.111936   9061\n",
       "3459   0.063351   3459\n",
       "4549   0.020534   4549\n",
       "9761   0.071641   9761\n",
       "4851   0.121941   4851\n",
       "9062   0.004079   9062\n",
       "11869  0.038638  11869\n",
       "12255  0.023962  12255\n",
       "2748   0.158208   2748\n",
       "4320   0.130297   4320\n",
       "11583  0.143343  11583\n",
       "4799   0.033953   4799\n",
       "9268   0.022682   9268\n",
       "10470  0.057413  10470\n",
       "9058   0.120599   9058"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivots = []\n",
    "print('Pivot values')\n",
    "for i in df_scores.index:\n",
    "    stock = i\n",
    "    df = d_stocks[stock]\n",
    "    \n",
    "    pivot = np.mean([np.min(df[df['pred'] == 1]['queue_imbalance']), \n",
    "                    np.max(df[df['pred'] == 0]['queue_imbalance'])])\n",
    "    pivots.append(pivot)\n",
    "df_scores['pivot'] = pivots\n",
    "df_scores[['pivot', 'stock']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_scores[['pivot', 'stock']]\n",
    "df_pivot['stock'] = df_pivot['stock'].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    15 non-null int64\n",
      "pivot         15 non-null float64\n",
      "stock         15 non-null int64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 440.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df_log = pd.read_csv('que_log_pivot.csv')\n",
    "df_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = pd.merge(df_pivot, df_log[['pivot', 'stock']], \n",
    "                    on='stock', suffixes=['', '_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pivot</th>\n",
       "      <th>pivot_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>0.111936</td>\n",
       "      <td>0.023023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0.063351</td>\n",
       "      <td>0.096860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>0.020534</td>\n",
       "      <td>0.032053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.071641</td>\n",
       "      <td>0.043341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>0.121941</td>\n",
       "      <td>0.089948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>0.038638</td>\n",
       "      <td>0.037273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>0.023962</td>\n",
       "      <td>0.046640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.158208</td>\n",
       "      <td>0.038263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0.130297</td>\n",
       "      <td>0.053965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.143343</td>\n",
       "      <td>0.046703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.033953</td>\n",
       "      <td>0.049480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.022682</td>\n",
       "      <td>0.018577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>0.057413</td>\n",
       "      <td>0.085225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>0.120599</td>\n",
       "      <td>0.031014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pivot  pivot_log\n",
       "stock                     \n",
       "9061   0.111936   0.023023\n",
       "3459   0.063351   0.096860\n",
       "4549   0.020534   0.032053\n",
       "9761   0.071641   0.043341\n",
       "4851   0.121941   0.089948\n",
       "9062   0.004079   0.012105\n",
       "11869  0.038638   0.037273\n",
       "12255  0.023962   0.046640\n",
       "2748   0.158208   0.038263\n",
       "4320   0.130297   0.053965\n",
       "11583  0.143343   0.046703\n",
       "4799   0.033953   0.049480\n",
       "9268   0.022682   0.018577\n",
       "10470  0.057413   0.085225\n",
       "9058   0.120599   0.031014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.index = df_pivot['stock']\n",
    "df_pivot.drop(columns=['stock'], inplace=True)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pivot.plot(kind='bar')\n",
    "plt.legend(['Pivot for QUE+SVM', 'Pivot for QUE+LOG'])\n",
    "plt.title('Decision Boundary Pivot values comparision')\n",
    "plt.ylabel('Pivot value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('que_svm_log_pivot_rbf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['stock'] = df_pivot.index\n",
    "df_pivot[['stock', 'pivot']].to_csv('que_svm_rbf_pivot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
