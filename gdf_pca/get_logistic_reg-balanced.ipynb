{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ast import literal_eval\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from lob_data_utils import lob, db_result, model, roc_results, stocks_numbers\n",
    "from lob_data_utils.svm_calculation import lob_svm\n",
    "import os\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 6929\n",
    "stocks = stocks_numbers.chosen_stocks\n",
    "should_csv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_scores(scores: dict) -> dict:\n",
    "    mean_scores = {}\n",
    "    for k, v in scores.items():\n",
    "        mean_scores[k] = np.mean(v)\n",
    "    return mean_scores\n",
    "\n",
    "def get_score_for_clf(clf, df_test):\n",
    "    x_test = df_test[['queue_imbalance']]\n",
    "    y_test = df_test['mid_price_indicator'].values\n",
    "    return model.test_model(clf, x_test, y_test)\n",
    "\n",
    "def get_score_for_clf_prev(clf, df_test):\n",
    "    x_test = df_test[['queue_imbalance', 'prev_queue_imbalance']]\n",
    "    y_test = df_test['mid_price_indicator'].values\n",
    "    return model.test_model(clf, x_test, y_test)\n",
    "\n",
    "class NullHyposthesisClassifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, a, b):\n",
    "        pass\n",
    "    def predict(self, df):\n",
    "        return np.array(np.ones(len(df)) * 1/2)\n",
    "\n",
    "class FakeClassifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, a, b):\n",
    "        pass\n",
    "    def predict(self, df):\n",
    "        pred = []\n",
    "        train_x = df['queue_imbalance'].values\n",
    "        for x in train_x:\n",
    "            if x <= 0.0:\n",
    "                pred.append(0)\n",
    "            else:\n",
    "                pred.append(1)\n",
    "        return np.array(pred)\n",
    "    \n",
    "def get_null_hyposthesis_classifier(stock, data_length):\n",
    "    \n",
    "    df, df_test = lob.load_prepared_data(\n",
    "    stock, data_dir='../data/prepared_balanced', length=data_length)\n",
    "\n",
    "    train_x = df[['queue_imbalance']]\n",
    "    y_train = df['mid_price_indicator']\n",
    "    a = np.unique(y_train)\n",
    "\n",
    "    clf = NullHyposthesisClassifier()\n",
    "    scores = model.validate_model(clf, train_x, y_train, print_debug=False)\n",
    "    res = {\n",
    "        **get_mean_scores(scores),\n",
    "        'stock': stock,\n",
    "        'kernel': 'null-hypothesis',\n",
    "    }\n",
    "    test_scores = get_score_for_clf(clf, df_test)\n",
    "    return {**res, **test_scores}\n",
    "\n",
    "def get_fake_classifier(stock, data_length):\n",
    "    \n",
    "    df, df_test = lob.load_prepared_data(\n",
    "    stock, data_dir='../data/prepared_balanced', length=data_length)\n",
    "\n",
    "    train_x = df[['queue_imbalance']]\n",
    "    y_train = df['mid_price_indicator']\n",
    "    a = np.unique(y_train)\n",
    "\n",
    "    clf = FakeClassifier()\n",
    "    scores = model.validate_model(clf, train_x, y_train, print_debug=False)\n",
    "    res = {\n",
    "        **get_mean_scores(scores),\n",
    "        'stock': stock,\n",
    "        'kernel': 'fake',\n",
    "    }\n",
    "    test_scores = get_score_for_clf(clf, df_test)\n",
    "    return {**res, **test_scores}\n",
    "\n",
    "def get_logistic_regression(stock, data_length):\n",
    "    df, df_test = lob.load_prepared_data(\n",
    "        stock, data_dir='../data/prepared_balanced', length=data_length)\n",
    "\n",
    "    train_x = df[['queue_imbalance']]\n",
    "    y_train = df['mid_price_indicator']\n",
    "    a = np.unique(y_train)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    scores = model.validate_model(clf, train_x, y_train, print_debug=False)\n",
    "    res = {\n",
    "        **get_mean_scores(scores),\n",
    "        'stock': stock,\n",
    "        'kernel': 'logistic-balanced',\n",
    "    }\n",
    "    test_scores = get_score_for_clf(clf, df_test)\n",
    "    return {**res, **test_scores}\n",
    "\n",
    "def get_logistic_regression_prev(stock, data_length):\n",
    "    df, df_test = lob.load_prepared_data(\n",
    "        stock, data_dir='../data/prepared_balanced', length=data_length)\n",
    "    df['prev_queue_imbalance'] = df['queue_imbalance'].shift()\n",
    "    df.dropna(inplace=True)\n",
    "    df_test['prev_queue_imbalance'] = df_test['queue_imbalance'].shift()\n",
    "    df_test.dropna(inplace=True)\n",
    "    train_x = df[['queue_imbalance', 'prev_queue_imbalance']]\n",
    "    y_train = df['mid_price_indicator']\n",
    "    a = np.unique(y_train)\n",
    "    clf = LogisticRegression()\n",
    "    scores = model.validate_model(clf, train_x, y_train, print_debug=False)\n",
    "    res = {\n",
    "        **get_mean_scores(scores),\n",
    "        'stock': stock,\n",
    "        'kernel': 'logistic-balanced',\n",
    "    }\n",
    "    test_scores = get_score_for_clf_prev(clf, df_test)\n",
    "    return {**res, **test_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748 Classification metrics can't handle a mix of continuous and binary targets\n"
     ]
    }
   ],
   "source": [
    "log_res = []\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        res = get_logistic_regression(stock, data_length)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(stock, e)\n",
    "    log_res.append(res)\n",
    "df_log_res = pd.DataFrame(log_res)\n",
    "df_log_res['stock'] = df_log_res['stock'].values.astype(np.int)\n",
    "df_log_res.index = df_log_res['stock'].values.astype(np.int)\n",
    "\n",
    "if should_csv:\n",
    "    df_log_res.to_csv('res_log_balanced_que.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_res = []\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        res = get_logistic_regression_prev(stock, data_length)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(stock, e)\n",
    "    log_res.append(res)\n",
    "df_log_res = pd.DataFrame(log_res)\n",
    "df_log_res['stock'] = df_log_res['stock'].values.astype(np.int)\n",
    "df_log_res.index = df_log_res['stock'].values.astype(np.int)\n",
    "\n",
    "if should_csv:\n",
    "    df_log_res.to_csv('res_log_balanced_prev_que.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748 Classification metrics can't handle a mix of continuous and binary targets\n"
     ]
    }
   ],
   "source": [
    "log_res = []\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        res = get_fake_classifier(stock, data_length)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(stock, e)\n",
    "    log_res.append(res)\n",
    "df_log_res = pd.DataFrame(log_res)\n",
    "df_log_res['stock'] = df_log_res['stock'].values.astype(np.int)\n",
    "df_log_res.index = df_log_res['stock'].values.astype(np.int)\n",
    "\n",
    "if should_csv:\n",
    "    df_log_res.to_csv('res_fake_balanced_que.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9061 Classification metrics can't handle a mix of binary and continuous targets\n",
      "3459 Classification metrics can't handle a mix of binary and continuous targets\n",
      "4549 Classification metrics can't handle a mix of binary and continuous targets\n",
      "9761 Classification metrics can't handle a mix of binary and continuous targets\n",
      "4851 Classification metrics can't handle a mix of binary and continuous targets\n",
      "9062 Classification metrics can't handle a mix of binary and continuous targets\n",
      "11869 Classification metrics can't handle a mix of binary and continuous targets\n",
      "12255 Classification metrics can't handle a mix of binary and continuous targets\n",
      "2748 Classification metrics can't handle a mix of binary and continuous targets\n",
      "4320 Classification metrics can't handle a mix of binary and continuous targets\n",
      "11583 Classification metrics can't handle a mix of binary and continuous targets\n",
      "4799 Classification metrics can't handle a mix of binary and continuous targets\n",
      "9268 Classification metrics can't handle a mix of binary and continuous targets\n",
      "10470 Classification metrics can't handle a mix of binary and continuous targets\n",
      "9058 Classification metrics can't handle a mix of binary and continuous targets\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'stock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stock'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-267c00848029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_log_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_log_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_log_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf_log_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_log_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stock'"
     ]
    }
   ],
   "source": [
    "log_res = []\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        res = get_null_hyposthesis_classifier(stock, data_length)\n",
    "        log_res.append(res)\n",
    "    except Exception as e:\n",
    "        print(stock, e)\n",
    "    \n",
    "df_log_res = pd.DataFrame(log_res)\n",
    "df_log_res['stock'] = df_log_res['stock'].values.astype(np.int)\n",
    "df_log_res.index = df_log_res['stock'].values.astype(np.int)\n",
    "\n",
    "if should_csv:\n",
    "    df_log_res.to_csv('res_null_hypothesis_balanced.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
